# 第一阶段：数学基础（2-4周）

## 概述

机器学习和深度学习的数学基础。不需要精通，但需要理解核心概念。

## 1. 线性代数（最重要）

### 核心概念
- [ ] 向量与矩阵运算
- [ ] 矩阵乘法与转置
- [ ] 特征值与特征向量
- [ ] 矩阵分解（SVD、PCA）
- [ ] 向量空间与基

### 在深度学习中的应用
- 神经网络的权重就是矩阵
- 前向传播就是矩阵乘法
- Attention机制的Q、K、V都是矩阵运算
- Embedding就是向量表示

### 推荐资源
| 资源 | 链接 |
|------|------|
| 3Blue1Brown线性代数 | https://www.3blue1brown.com/topics/linear-algebra |
| MIT 18.06 | https://ocw.mit.edu/courses/18-06sc-linear-algebra-fall-2011/ |

---

## 2. 微积分

### 核心概念
- [ ] 导数与偏导数
- [ ] 链式法则（反向传播的基础）
- [ ] 梯度与梯度下降
- [ ] 多变量微积分

### 在深度学习中的应用
- 反向传播算法依赖链式法则
- 优化器（SGD、Adam）基于梯度
- 损失函数的最小化

### 推荐资源
| 资源 | 链接 |
|------|------|
| 3Blue1Brown微积分 | https://www.3blue1brown.com/topics/calculus |

---

## 3. 概率与统计

### 核心概念
- [ ] 概率分布（正态、伯努利、Softmax）
- [ ] 条件概率与贝叶斯定理
- [ ] 期望、方差、协方差
- [ ] 最大似然估计（MLE）
- [ ] 信息论基础（熵、交叉熵、KL散度）

### 在深度学习中的应用
- 交叉熵损失函数
- Softmax概率输出
- Dropout的概率解释
- VAE、扩散模型的概率基础

---

## 4. 最优化

### 核心概念
- [ ] 凸优化与非凸优化
- [ ] 梯度下降法
- [ ] 学习率与收敛
- [ ] 局部最优与全局最优

---

## 学习建议

1. **不要陷入数学细节** - 理解直觉比推导公式更重要
2. **结合代码学习** - 用NumPy实现矩阵运算
3. **用到再学** - 遇到不懂的数学概念再深入

## 快速检验

能回答以下问题说明基础足够：
1. 为什么神经网络需要非线性激活函数？
2. 反向传播是如何利用链式法则的？
3. 为什么使用交叉熵而不是MSE作为分类损失？
4. Softmax的数学含义是什么？
