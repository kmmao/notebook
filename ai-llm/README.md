# AI与大语言模型（LLM）学习路线（2025版）

> 目标：从基础到实战，掌握AI/LLM核心技术

## 学习路径概览

| 阶段 | 内容 | 预计时间 |
|------|------|----------|
| [01-数学基础](./01-数学基础/) | 线性代数、概率统计、微积分 | 2-4周 |
| [02-机器学习基础](./02-机器学习基础/) | 监督/无监督学习、经典算法 | 4-6周 |
| [03-深度学习基础](./03-深度学习基础/) | 神经网络、CNN、RNN | 4-6周 |
| [04-Transformer架构](./04-Transformer架构/) | Attention机制、Transformer原理 | 2-4周 |
| [05-LLM原理与训练](./05-LLM原理与训练/) | 预训练、Tokenization、Scaling Laws | 4-6周 |
| [06-Prompt-Engineering](./06-Prompt-Engineering/) | 提示词工程、Chain-of-Thought | 2-3周 |
| [07-RAG系统](./07-RAG系统/) | 检索增强生成、向量数据库 | 3-4周 |
| [08-Fine-Tuning微调](./08-Fine-Tuning微调/) | LoRA、QLoRA、RLHF | 4-6周 |
| [09-LLM应用开发](./09-LLM应用开发/) | LangChain、Agent、部署 | 4-6周 |
| [10-前沿技术](./10-前沿技术/) | 多模态、推理模型、MoE | 持续 |
| [11-工具与框架](./11-工具与框架/) | PyTorch、HuggingFace、vLLM | - |
| [12-学习资源](./12-学习资源/) | 课程、论文、社区 | - |

## Sebastian Raschka的2025 LLM路线图

> LLM领域权威Sebastian Raschka推荐的学习路径：

1. **从零编写并训练自己的LLM** - 真正理解底层原理
2. **使用生产级框架训练模型** - 掌握实际工程能力
3. **了解真实世界LLM应用的全局考量** - 系统思维

## 学习阶段划分

### 🔍 Part 1: 基础理论（12-20周）
- 神经网络基础
- Transformer架构
- Tokenization与Embeddings
- Attention机制

### 🧬 Part 2: 模型训练（16-28周）
- 数据准备与预处理
- 预训练（Pre-training）
- 微调（Fine-tuning）
- RLHF与偏好对齐

### ⚙️ Part 3: 高级专题（20-36周）
- 模型评估
- 推理与量化
- 推理优化
- 架构变体

### 🚀 Part 4: 工程与应用（持续）
- 生产部署
- RAG系统
- Agent开发
- 多模态应用

## 核心原则

1. **动手实现** - 看论文不如自己写一遍Transformer
2. **理解原理** - 知其然更要知其所以然
3. **跟踪前沿** - 这个领域变化极快，保持学习
4. **项目驱动** - 以实际项目巩固所学
